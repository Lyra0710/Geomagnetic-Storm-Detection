{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Define the paths to the 'Data' and 'CSV' folders\n",
    "data_folder = \"../Level1-data/\"\n",
    "csv_folder = \"../Level1-mg-CSV-11days/\"\n",
    "\n",
    "# Create the 'CSV' folder if it doesn't exist\n",
    "if not os.path.exists(csv_folder):\n",
    "    os.makedirs(csv_folder)\n",
    "\n",
    "# Check for files with .nc extension in the 'Data' folder\n",
    "nc_files = glob.glob(os.path.join(data_folder, \"*.nc\"))\n",
    "\n",
    "if not nc_files:\n",
    "    print(\"No .nc files found in the 'Data' folder.\")\n",
    "else:\n",
    "    # Loop through the .nc files and convert them to CSV with batch processing\n",
    "    chunk_size = 5000\n",
    "    for nc_file in nc_files:\n",
    "        file_name = os.path.basename(nc_file)  # Get the file name without path\n",
    "        csv_file = os.path.join(csv_folder, os.path.splitext(file_name)[0] + \".csv\")\n",
    "\n",
    "        try:\n",
    "            # Open the .nc file using netCDF4\n",
    "            nc = Dataset(nc_file, 'r')\n",
    "\n",
    "            # Create a Pandas DataFrame in chunks and save to CSV\n",
    "            for i in range(0, len(nc.dimensions['time']), chunk_size):\n",
    "                chunk_end = min(i + chunk_size, len(nc.dimensions['time']))\n",
    "                variable_data = {}\n",
    "\n",
    "                # Extract variables and their data for the current chunk\n",
    "                for var_name, var in nc.variables.items():\n",
    "                    variable_data[var_name] = var[i:chunk_end]\n",
    "\n",
    "                # Create a Pandas DataFrame from the variable data\n",
    "                df = pd.DataFrame(variable_data)\n",
    "\n",
    "                # Save the DataFrame as a CSV file\n",
    "                if i == 0:\n",
    "                    df.to_csv(csv_file, mode='w', index=False)\n",
    "                else:\n",
    "                    df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "\n",
    "            print(f\"Converted {file_name} to {os.path.basename(csv_file)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {file_name}: {str(e)}\")\n",
    "\n",
    "# Now, create a Pandas DataFrame from the CSV files in the 'CSV' folder\n",
    "csv_files = glob.glob(os.path.join(csv_folder, \"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the 'CSV' folder.\")\n",
    "else:\n",
    "    # Concatenate the CSV files into a Pandas DataFrame\n",
    "    df = pd.concat(map(pd.read_csv, csv_files))\n",
    "    print(\"Concatenation of CSV files completed.\")\n",
    "\n",
    "# Now, 'df' contains the combined data from all CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "common_times = df1[df1['time'].isin(df2['time'])]\n",
    "\n",
    "merged_df = common_times.merge(df1, on='time')\n",
    "\n",
    "merged_df.to_csv('../Dataset/final_mg.csv', index=False)\n",
    "\n",
    "print(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
