2023-10-07 15:36:08

--------------------------------------------------
Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression

Outputs:

--------------------------------------------------

Code:
df = pd.read_csv('../Datasets/Merged_Dataset.csv')
df1 = df.copy()

Outputs:

--------------------------------------------------

Code:
print(df.info())

Outputs:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1108 entries, 0 to 1107
Data columns (total 30 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   Timestamp  1108 non-null   object 
 1   Source     1108 non-null   int64  
 2   Bt-med     1108 non-null   float64
 3   Bt-min     1108 non-null   float64
 4   Bt-max     1108 non-null   float64
 5   Bx-med     1108 non-null   float64
 6   Bx-min     1108 non-null   float64
 7   Bx-max     1108 non-null   float64
 8   By-med     1108 non-null   float64
 9   By-min     1108 non-null   float64
 10  By-max     1108 non-null   float64
 11  Bz-med     1108 non-null   float64
 12  Bz-min     1108 non-null   float64
 13  Bz-max     1108 non-null   float64
 14  Phi-mean   1108 non-null   float64
 15  Phi-min    1108 non-null   float64
 16  Phi-max    1108 non-null   float64
 17  Theta-med  1108 non-null   float64
 18  Theta-min  1108 non-null   float64
 19  Theta-max  1108 non-null   float64
 20  Dens-med   1108 non-null   float64
 21  Dens-min   1108 non-null   float64
 22  Dens-max   1108 non-null   float64
 23  Speed-med  1108 non-null   float64
 24  Speed-min  1108 non-null   float64
 25  Speed-max  1108 non-null   float64
 26  Temp-med   1108 non-null   int64  
 27  Temp-min   1108 non-null   int64  
 28  Temp-max   1108 non-null   int64  
 29  Kp         1108 non-null   float64
dtypes: float64(25), int64(4), object(1)
memory usage: 259.8+ KB
None

--------------------------------------------------

Code:
print(df1.describe())

Outputs:
            Source        Bt-med        Bt-min        Bt-max        Bx-med  \
count  1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean      0.998195   -173.829350   -175.541977   -172.457879   -180.260866   
std       0.060084   4246.916048   4246.842839   4246.975038   4246.642889   
min      -1.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       1.000000      4.980000      3.645000      5.780000     -2.805000   
50%       1.000000      5.940000      4.690000      6.995000      0.740000   
75%       1.000000      7.492500      5.840000      9.142500      3.182500   
max       1.000000     32.440000     28.460000     33.990000     10.920000   

             Bx-min        Bx-max        By-med        By-min        By-max  \
count   1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean    -184.039675   -176.684233   -180.786173   -184.882987   -176.389305   
std     4246.481880   4246.794863   4246.621208   4246.446584   4246.807973   
min   -99999.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       -5.682500      1.840000     -3.180000     -6.212500      1.707500   
50%       -3.755000      4.160000     -0.910000     -4.470000      4.165000   
75%       -1.247500      5.730000      2.830000     -2.177500      5.945000   
max        4.560000     28.070000     23.400000     15.190000     28.870000   

       ...      Dens-med      Dens-min      Dens-max     Speed-med  \
count  ...   1108.000000   1108.000000   1108.000000   1108.000000   
mean   ...   -173.824368   -176.856733   -169.576796    265.974278   
std    ...   4246.916989   4246.787163   4247.101295   4266.182906   
min    ... -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%    ...      3.807500      1.130000      6.550000    400.000000   
50%    ...      6.070000      3.220000      9.610000    446.600000   
75%    ...      9.180000      5.430000     13.102500    494.525000   
max    ...     29.790000     16.380000     71.160000    660.500000   

          Speed-min     Speed-max      Temp-med       Temp-min      Temp-max  \
count   1108.000000   1108.000000  1.108000e+03    1108.000000  1.108000e+03   
mean     235.027076    300.955054  1.622780e+05   69297.582130  3.380935e+05   
std     4264.792553   4267.743731  1.496670e+05   78414.146887  2.668830e+05   
min   -99999.000000 -99999.000000 -9.999900e+04  -99999.000000 -9.999900e+04   
25%      375.800000    429.925000  5.826825e+04   11251.750000  1.545115e+05   
50%      415.800000    480.000000  1.206725e+05   46096.000000  2.770000e+05   
75%      467.050000    528.550000  2.240372e+05  103690.500000  4.484000e+05   
max      621.000000    704.500000  1.308885e+06  599020.000000  2.391534e+06   

               Kp  
count  1108.00000  
mean      2.03068  
std       1.26729  
min       0.00000  
25%       1.00000  
50%       2.00000  
75%       2.66700  
max       8.33300  

[8 rows x 29 columns]

--------------------------------------------------

Code:
print(df1.iloc[:, 1:].corr()['Kp'])

Outputs:
Source      -0.007173
Bt-med      -0.004234
Bt-min      -0.004403
Bt-max      -0.004116
Bx-med      -0.004494
Bx-min      -0.004747
Bx-max      -0.004315
By-med      -0.004663
By-min      -0.004894
By-max      -0.004341
Bz-med      -0.004822
Bz-min      -0.005019
Bz-max      -0.004407
Phi-mean    -0.002292
Phi-min     -0.007209
Phi-max     -0.002063
Theta-med   -0.006445
Theta-min   -0.006769
Theta-max   -0.004858
Dens-med    -0.004262
Dens-min    -0.004460
Dens-max    -0.003942
Speed-med    0.000860
Speed-min    0.000172
Speed-max    0.001234
Temp-med     0.060189
Temp-min    -0.017895
Temp-max     0.069590
Kp           1.000000
Name: Kp, dtype: float64

--------------------------------------------------

Code:
x = df1.iloc[:, 1:-1]
y = df1.iloc[:, -1]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)

Outputs:

--------------------------------------------------

Code:
x.to_csv('../Code_only/train-tests/x.csv', index = False)
y.to_csv('../Code_only/train-tests/y.csv', index = False)

Outputs:

--------------------------------------------------

Code:
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

multi = LinearRegression().fit(x_train, y_train)
y_pred = multi.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

print(y_test)
y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")

Outputs:
1050    2.333
982     3.333
766     2.000
491     0.667
457     0.333
        ...  
841     1.333
95      0.667
113     2.000
725     0.667
37      0.667
Name: Kp, Length: 333, dtype: float64
Mean Absolute Error (MAE): 0.6790486276752579
Mean Squared Error (MSE): 0.7640443306957228
Root Mean Squared Error (RMSE): 0.8740962937203902
R-squared (R2) Score: 0.5195210365442081

--------------------------------------------------

Code:
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=3)
x_poly = poly.fit_transform(x_train)
reg = LinearRegression().fit(x_poly, y_train)

y_pred = reg.predict(poly.fit_transform(x_test))
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 8.442562673452013
Mean Squared Error (MSE): 744.1389348409579
Root Mean Squared Error (RMSE): 27.27891007428555
R-squared (R2) Score: -466.96120292380056

--------------------------------------------------

Code:
from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.9559879879879881
Mean Squared Error (MSE): 1.5292567387387386
Root Mean Squared Error (RMSE): 1.2366312056303361
R-squared (R2) Score: 0.03830751284038392

--------------------------------------------------

Code:
from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 20, random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.7335405405405405
Mean Squared Error (MSE): 0.8653285311861862
Root Mean Squared Error (RMSE): 0.9302303645797563
R-squared (R2) Score: 0.4558271830451668

--------------------------------------------------

Code:
# SVM
# ARIMA model (NN)
# LSTM
# Multivariate LSTM (link on slack)
# Multistep LSTM (link sent in slack)
# GRU model (Gated Recurrent Unit)
# Attention Mechanism
# Vanilla LSTM

# Ananya's research papers also included Deep GPR (Gaussian Process Regression)

Outputs:

--------------------------------------------------

Code:
import datetime
log_file_path = '../Logs/models_log.txt'
def log_output_to_file(output_text, log_file_path):
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    divider = '-' * 40  # Line divider
    
    with open(log_file_path, 'a') as log_file:
        log_file.write(f'{timestamp}\n')
        log_file.write(divider + '\n')
        log_file.write(output_text)
        log_file.write('\n\n')


Outputs:

--------------------------------------------------


--------------------------------------------------

--------------------------------------------------

2023-10-07 15:59:20

--------------------------------------------------
Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression

Outputs:

--------------------------------------------------

Code:
df = pd.read_csv('../Datasets/Merged_Dataset.csv')
df1 = df.copy()

Outputs:

--------------------------------------------------

Code:
print(df.info())

Outputs:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1108 entries, 0 to 1107
Data columns (total 30 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   Timestamp  1108 non-null   object 
 1   Source     1108 non-null   int64  
 2   Bt-med     1108 non-null   float64
 3   Bt-min     1108 non-null   float64
 4   Bt-max     1108 non-null   float64
 5   Bx-med     1108 non-null   float64
 6   Bx-min     1108 non-null   float64
 7   Bx-max     1108 non-null   float64
 8   By-med     1108 non-null   float64
 9   By-min     1108 non-null   float64
 10  By-max     1108 non-null   float64
 11  Bz-med     1108 non-null   float64
 12  Bz-min     1108 non-null   float64
 13  Bz-max     1108 non-null   float64
 14  Phi-mean   1108 non-null   float64
 15  Phi-min    1108 non-null   float64
 16  Phi-max    1108 non-null   float64
 17  Theta-med  1108 non-null   float64
 18  Theta-min  1108 non-null   float64
 19  Theta-max  1108 non-null   float64
 20  Dens-med   1108 non-null   float64
 21  Dens-min   1108 non-null   float64
 22  Dens-max   1108 non-null   float64
 23  Speed-med  1108 non-null   float64
 24  Speed-min  1108 non-null   float64
 25  Speed-max  1108 non-null   float64
 26  Temp-med   1108 non-null   int64  
 27  Temp-min   1108 non-null   int64  
 28  Temp-max   1108 non-null   int64  
 29  Kp         1108 non-null   float64
dtypes: float64(25), int64(4), object(1)
memory usage: 259.8+ KB
None

--------------------------------------------------

Code:
print(df1.describe())

Outputs:
            Source        Bt-med        Bt-min        Bt-max        Bx-med  \
count  1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean      0.998195   -173.829350   -175.541977   -172.457879   -180.260866   
std       0.060084   4246.916048   4246.842839   4246.975038   4246.642889   
min      -1.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       1.000000      4.980000      3.645000      5.780000     -2.805000   
50%       1.000000      5.940000      4.690000      6.995000      0.740000   
75%       1.000000      7.492500      5.840000      9.142500      3.182500   
max       1.000000     32.440000     28.460000     33.990000     10.920000   

             Bx-min        Bx-max        By-med        By-min        By-max  \
count   1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean    -184.039675   -176.684233   -180.786173   -184.882987   -176.389305   
std     4246.481880   4246.794863   4246.621208   4246.446584   4246.807973   
min   -99999.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       -5.682500      1.840000     -3.180000     -6.212500      1.707500   
50%       -3.755000      4.160000     -0.910000     -4.470000      4.165000   
75%       -1.247500      5.730000      2.830000     -2.177500      5.945000   
max        4.560000     28.070000     23.400000     15.190000     28.870000   

       ...      Dens-med      Dens-min      Dens-max     Speed-med  \
count  ...   1108.000000   1108.000000   1108.000000   1108.000000   
mean   ...   -173.824368   -176.856733   -169.576796    265.974278   
std    ...   4246.916989   4246.787163   4247.101295   4266.182906   
min    ... -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%    ...      3.807500      1.130000      6.550000    400.000000   
50%    ...      6.070000      3.220000      9.610000    446.600000   
75%    ...      9.180000      5.430000     13.102500    494.525000   
max    ...     29.790000     16.380000     71.160000    660.500000   

          Speed-min     Speed-max      Temp-med       Temp-min      Temp-max  \
count   1108.000000   1108.000000  1.108000e+03    1108.000000  1.108000e+03   
mean     235.027076    300.955054  1.622780e+05   69297.582130  3.380935e+05   
std     4264.792553   4267.743731  1.496670e+05   78414.146887  2.668830e+05   
min   -99999.000000 -99999.000000 -9.999900e+04  -99999.000000 -9.999900e+04   
25%      375.800000    429.925000  5.826825e+04   11251.750000  1.545115e+05   
50%      415.800000    480.000000  1.206725e+05   46096.000000  2.770000e+05   
75%      467.050000    528.550000  2.240372e+05  103690.500000  4.484000e+05   
max      621.000000    704.500000  1.308885e+06  599020.000000  2.391534e+06   

               Kp  
count  1108.00000  
mean      2.03068  
std       1.26729  
min       0.00000  
25%       1.00000  
50%       2.00000  
75%       2.66700  
max       8.33300  

[8 rows x 29 columns]

--------------------------------------------------

Code:
print(df1.iloc[:, 1:].corr()['Kp'])

Outputs:
Source      -0.007173
Bt-med      -0.004234
Bt-min      -0.004403
Bt-max      -0.004116
Bx-med      -0.004494
Bx-min      -0.004747
Bx-max      -0.004315
By-med      -0.004663
By-min      -0.004894
By-max      -0.004341
Bz-med      -0.004822
Bz-min      -0.005019
Bz-max      -0.004407
Phi-mean    -0.002292
Phi-min     -0.007209
Phi-max     -0.002063
Theta-med   -0.006445
Theta-min   -0.006769
Theta-max   -0.004858
Dens-med    -0.004262
Dens-min    -0.004460
Dens-max    -0.003942
Speed-med    0.000860
Speed-min    0.000172
Speed-max    0.001234
Temp-med     0.060189
Temp-min    -0.017895
Temp-max     0.069590
Kp           1.000000
Name: Kp, dtype: float64

--------------------------------------------------

Code:
x = df1.iloc[:, 1:-1]
y = df1.iloc[:, -1]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)

Outputs:

--------------------------------------------------

Code:
x.to_csv('../Code_only/train-tests/x.csv', index = False)
y.to_csv('../Code_only/train-tests/y.csv', index = False)

Outputs:

--------------------------------------------------

Code:
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

multi = LinearRegression().fit(x_train, y_train)
y_pred = multi.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

print(y_test)
y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")

Outputs:
1050    2.333
982     3.333
766     2.000
491     0.667
457     0.333
        ...  
841     1.333
95      0.667
113     2.000
725     0.667
37      0.667
Name: Kp, Length: 333, dtype: float64
Mean Absolute Error (MAE): 0.6790486276752579
Mean Squared Error (MSE): 0.7640443306957228
Root Mean Squared Error (RMSE): 0.8740962937203902
R-squared (R2) Score: 0.5195210365442081

--------------------------------------------------

Code:
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=3)
x_poly = poly.fit_transform(x_train)
reg = LinearRegression().fit(x_poly, y_train)

y_pred = reg.predict(poly.fit_transform(x_test))
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 8.442562673452013
Mean Squared Error (MSE): 744.1389348409579
Root Mean Squared Error (RMSE): 27.27891007428555
R-squared (R2) Score: -466.96120292380056

--------------------------------------------------

Code:
from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.9559879879879881
Mean Squared Error (MSE): 1.5292567387387386
Root Mean Squared Error (RMSE): 1.2366312056303361
R-squared (R2) Score: 0.03830751284038392

--------------------------------------------------

Code:
from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 20, random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.7335405405405405
Mean Squared Error (MSE): 0.8653285311861862
Root Mean Squared Error (RMSE): 0.9302303645797563
R-squared (R2) Score: 0.4558271830451668

--------------------------------------------------

Code:
# SVM
# ARIMA model (NN)
# LSTM
# Multivariate LSTM (link on slack)
# Multistep LSTM (link sent in slack)
# GRU model (Gated Recurrent Unit)
# Attention Mechanism
# Vanilla LSTM

# Ananya's research papers also included Deep GPR (Gaussian Process Regression)

Outputs:

--------------------------------------------------

Code:
import datetime
log_file_path = '../Logs/models_log.txt'
def log_output_to_file(output_text, log_file_path):
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    divider = '-' * 40  # Line divider
    
    with open(log_file_path, 'a') as log_file:
        log_file.write(f'{timestamp}\n')
        log_file.write(divider + '\n')
        log_file.write(output_text)
        log_file.write('\n\n')


Outputs:

--------------------------------------------------


--------------------------------------------------

--------------------------------------------------

2023-10-07 16:01:53

--------------------------------------------------
Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression

Outputs:

--------------------------------------------------

Code:
df = pd.read_csv('../Datasets/Merged_Dataset.csv')
df1 = df.copy()

Outputs:

--------------------------------------------------

Code:
print(df.info())

Outputs:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1108 entries, 0 to 1107
Data columns (total 30 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   Timestamp  1108 non-null   object 
 1   Source     1108 non-null   int64  
 2   Bt-med     1108 non-null   float64
 3   Bt-min     1108 non-null   float64
 4   Bt-max     1108 non-null   float64
 5   Bx-med     1108 non-null   float64
 6   Bx-min     1108 non-null   float64
 7   Bx-max     1108 non-null   float64
 8   By-med     1108 non-null   float64
 9   By-min     1108 non-null   float64
 10  By-max     1108 non-null   float64
 11  Bz-med     1108 non-null   float64
 12  Bz-min     1108 non-null   float64
 13  Bz-max     1108 non-null   float64
 14  Phi-mean   1108 non-null   float64
 15  Phi-min    1108 non-null   float64
 16  Phi-max    1108 non-null   float64
 17  Theta-med  1108 non-null   float64
 18  Theta-min  1108 non-null   float64
 19  Theta-max  1108 non-null   float64
 20  Dens-med   1108 non-null   float64
 21  Dens-min   1108 non-null   float64
 22  Dens-max   1108 non-null   float64
 23  Speed-med  1108 non-null   float64
 24  Speed-min  1108 non-null   float64
 25  Speed-max  1108 non-null   float64
 26  Temp-med   1108 non-null   int64  
 27  Temp-min   1108 non-null   int64  
 28  Temp-max   1108 non-null   int64  
 29  Kp         1108 non-null   float64
dtypes: float64(25), int64(4), object(1)
memory usage: 259.8+ KB
None

--------------------------------------------------

Code:
print(df1.describe())

Outputs:
            Source        Bt-med        Bt-min        Bt-max        Bx-med  \
count  1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean      0.998195   -173.829350   -175.541977   -172.457879   -180.260866   
std       0.060084   4246.916048   4246.842839   4246.975038   4246.642889   
min      -1.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       1.000000      4.980000      3.645000      5.780000     -2.805000   
50%       1.000000      5.940000      4.690000      6.995000      0.740000   
75%       1.000000      7.492500      5.840000      9.142500      3.182500   
max       1.000000     32.440000     28.460000     33.990000     10.920000   

             Bx-min        Bx-max        By-med        By-min        By-max  \
count   1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean    -184.039675   -176.684233   -180.786173   -184.882987   -176.389305   
std     4246.481880   4246.794863   4246.621208   4246.446584   4246.807973   
min   -99999.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       -5.682500      1.840000     -3.180000     -6.212500      1.707500   
50%       -3.755000      4.160000     -0.910000     -4.470000      4.165000   
75%       -1.247500      5.730000      2.830000     -2.177500      5.945000   
max        4.560000     28.070000     23.400000     15.190000     28.870000   

       ...      Dens-med      Dens-min      Dens-max     Speed-med  \
count  ...   1108.000000   1108.000000   1108.000000   1108.000000   
mean   ...   -173.824368   -176.856733   -169.576796    265.974278   
std    ...   4246.916989   4246.787163   4247.101295   4266.182906   
min    ... -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%    ...      3.807500      1.130000      6.550000    400.000000   
50%    ...      6.070000      3.220000      9.610000    446.600000   
75%    ...      9.180000      5.430000     13.102500    494.525000   
max    ...     29.790000     16.380000     71.160000    660.500000   

          Speed-min     Speed-max      Temp-med       Temp-min      Temp-max  \
count   1108.000000   1108.000000  1.108000e+03    1108.000000  1.108000e+03   
mean     235.027076    300.955054  1.622780e+05   69297.582130  3.380935e+05   
std     4264.792553   4267.743731  1.496670e+05   78414.146887  2.668830e+05   
min   -99999.000000 -99999.000000 -9.999900e+04  -99999.000000 -9.999900e+04   
25%      375.800000    429.925000  5.826825e+04   11251.750000  1.545115e+05   
50%      415.800000    480.000000  1.206725e+05   46096.000000  2.770000e+05   
75%      467.050000    528.550000  2.240372e+05  103690.500000  4.484000e+05   
max      621.000000    704.500000  1.308885e+06  599020.000000  2.391534e+06   

               Kp  
count  1108.00000  
mean      2.03068  
std       1.26729  
min       0.00000  
25%       1.00000  
50%       2.00000  
75%       2.66700  
max       8.33300  

[8 rows x 29 columns]

--------------------------------------------------

Code:
print(df1.iloc[:, 1:].corr()['Kp'])

Outputs:
Source      -0.007173
Bt-med      -0.004234
Bt-min      -0.004403
Bt-max      -0.004116
Bx-med      -0.004494
Bx-min      -0.004747
Bx-max      -0.004315
By-med      -0.004663
By-min      -0.004894
By-max      -0.004341
Bz-med      -0.004822
Bz-min      -0.005019
Bz-max      -0.004407
Phi-mean    -0.002292
Phi-min     -0.007209
Phi-max     -0.002063
Theta-med   -0.006445
Theta-min   -0.006769
Theta-max   -0.004858
Dens-med    -0.004262
Dens-min    -0.004460
Dens-max    -0.003942
Speed-med    0.000860
Speed-min    0.000172
Speed-max    0.001234
Temp-med     0.060189
Temp-min    -0.017895
Temp-max     0.069590
Kp           1.000000
Name: Kp, dtype: float64

--------------------------------------------------

Code:
x = df1.iloc[:, 1:-1]
y = df1.iloc[:, -1]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)

Outputs:

--------------------------------------------------

Code:
x.to_csv('../Code_only/train-tests/x.csv', index = False)
y.to_csv('../Code_only/train-tests/y.csv', index = False)

Outputs:

--------------------------------------------------

Code:
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

multi = LinearRegression().fit(x_train, y_train)
y_pred = multi.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

print(y_test)
y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")

Outputs:
1050    2.333
982     3.333
766     2.000
491     0.667
457     0.333
        ...  
841     1.333
95      0.667
113     2.000
725     0.667
37      0.667
Name: Kp, Length: 333, dtype: float64
Mean Absolute Error (MAE): 0.6790486276752579
Mean Squared Error (MSE): 0.7640443306957228
Root Mean Squared Error (RMSE): 0.8740962937203902
R-squared (R2) Score: 0.5195210365442081

--------------------------------------------------

Code:
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=3)
x_poly = poly.fit_transform(x_train)
reg = LinearRegression().fit(x_poly, y_train)

y_pred = reg.predict(poly.fit_transform(x_test))
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 8.442562673452013
Mean Squared Error (MSE): 744.1389348409579
Root Mean Squared Error (RMSE): 27.27891007428555
R-squared (R2) Score: -466.96120292380056

--------------------------------------------------

Code:
from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.9559879879879881
Mean Squared Error (MSE): 1.5292567387387386
Root Mean Squared Error (RMSE): 1.2366312056303361
R-squared (R2) Score: 0.03830751284038392

--------------------------------------------------

Code:
from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 20, random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.7335405405405405
Mean Squared Error (MSE): 0.8653285311861862
Root Mean Squared Error (RMSE): 0.9302303645797563
R-squared (R2) Score: 0.4558271830451668

--------------------------------------------------

Code:
# SVM
# ARIMA model (NN)
# LSTM
# Multivariate LSTM (link on slack)
# Multistep LSTM (link sent in slack)
# GRU model (Gated Recurrent Unit)
# Attention Mechanism
# Vanilla LSTM

# Ananya's research papers also included Deep GPR (Gaussian Process Regression)

Outputs:

--------------------------------------------------

Code:
import datetime
log_file_path = '../Logs/models_log.txt'
def log_output_to_file(output_text, log_file_path):
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    divider = '-' * 40  # Line divider
    
    with open(log_file_path, 'a') as log_file:
        log_file.write(f'{timestamp}\n')
        log_file.write(divider + '\n')
        log_file.write(output_text)
        log_file.write('\n\n')


Outputs:

--------------------------------------------------


--------------------------------------------------

--------------------------------------------------

2023-10-07 18:22:03

--------------------------------------------------
Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression

Outputs:

--------------------------------------------------

Code:
df = pd.read_csv('../Datasets/Merged_Dataset.csv')
df1 = df.copy()

Outputs:

--------------------------------------------------

Code:
print(df.info())

Outputs:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1108 entries, 0 to 1107
Data columns (total 30 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   Timestamp  1108 non-null   object 
 1   Source     1108 non-null   int64  
 2   Bt-med     1108 non-null   float64
 3   Bt-min     1108 non-null   float64
 4   Bt-max     1108 non-null   float64
 5   Bx-med     1108 non-null   float64
 6   Bx-min     1108 non-null   float64
 7   Bx-max     1108 non-null   float64
 8   By-med     1108 non-null   float64
 9   By-min     1108 non-null   float64
 10  By-max     1108 non-null   float64
 11  Bz-med     1108 non-null   float64
 12  Bz-min     1108 non-null   float64
 13  Bz-max     1108 non-null   float64
 14  Phi-mean   1108 non-null   float64
 15  Phi-min    1108 non-null   float64
 16  Phi-max    1108 non-null   float64
 17  Theta-med  1108 non-null   float64
 18  Theta-min  1108 non-null   float64
 19  Theta-max  1108 non-null   float64
 20  Dens-med   1108 non-null   float64
 21  Dens-min   1108 non-null   float64
 22  Dens-max   1108 non-null   float64
 23  Speed-med  1108 non-null   float64
 24  Speed-min  1108 non-null   float64
 25  Speed-max  1108 non-null   float64
 26  Temp-med   1108 non-null   int64  
 27  Temp-min   1108 non-null   int64  
 28  Temp-max   1108 non-null   int64  
 29  Kp         1108 non-null   float64
dtypes: float64(25), int64(4), object(1)
memory usage: 259.8+ KB
None

--------------------------------------------------

Code:
print(df1.describe())

Outputs:
            Source        Bt-med        Bt-min        Bt-max        Bx-med  \
count  1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean      0.998195   -173.829350   -175.541977   -172.457879   -180.260866   
std       0.060084   4246.916048   4246.842839   4246.975038   4246.642889   
min      -1.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       1.000000      4.980000      3.645000      5.780000     -2.805000   
50%       1.000000      5.940000      4.690000      6.995000      0.740000   
75%       1.000000      7.492500      5.840000      9.142500      3.182500   
max       1.000000     32.440000     28.460000     33.990000     10.920000   

             Bx-min        Bx-max        By-med        By-min        By-max  \
count   1108.000000   1108.000000   1108.000000   1108.000000   1108.000000   
mean    -184.039675   -176.684233   -180.786173   -184.882987   -176.389305   
std     4246.481880   4246.794863   4246.621208   4246.446584   4246.807973   
min   -99999.000000 -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%       -5.682500      1.840000     -3.180000     -6.212500      1.707500   
50%       -3.755000      4.160000     -0.910000     -4.470000      4.165000   
75%       -1.247500      5.730000      2.830000     -2.177500      5.945000   
max        4.560000     28.070000     23.400000     15.190000     28.870000   

       ...      Dens-med      Dens-min      Dens-max     Speed-med  \
count  ...   1108.000000   1108.000000   1108.000000   1108.000000   
mean   ...   -173.824368   -176.856733   -169.576796    265.974278   
std    ...   4246.916989   4246.787163   4247.101295   4266.182906   
min    ... -99999.000000 -99999.000000 -99999.000000 -99999.000000   
25%    ...      3.807500      1.130000      6.550000    400.000000   
50%    ...      6.070000      3.220000      9.610000    446.600000   
75%    ...      9.180000      5.430000     13.102500    494.525000   
max    ...     29.790000     16.380000     71.160000    660.500000   

          Speed-min     Speed-max      Temp-med       Temp-min      Temp-max  \
count   1108.000000   1108.000000  1.108000e+03    1108.000000  1.108000e+03   
mean     235.027076    300.955054  1.622780e+05   69297.582130  3.380935e+05   
std     4264.792553   4267.743731  1.496670e+05   78414.146887  2.668830e+05   
min   -99999.000000 -99999.000000 -9.999900e+04  -99999.000000 -9.999900e+04   
25%      375.800000    429.925000  5.826825e+04   11251.750000  1.545115e+05   
50%      415.800000    480.000000  1.206725e+05   46096.000000  2.770000e+05   
75%      467.050000    528.550000  2.240372e+05  103690.500000  4.484000e+05   
max      621.000000    704.500000  1.308885e+06  599020.000000  2.391534e+06   

               Kp  
count  1108.00000  
mean      2.03068  
std       1.26729  
min       0.00000  
25%       1.00000  
50%       2.00000  
75%       2.66700  
max       8.33300  

[8 rows x 29 columns]

--------------------------------------------------

Code:
print(df1.iloc[:, 1:].corr()['Kp'])

Outputs:
Source      -0.007173
Bt-med      -0.004234
Bt-min      -0.004403
Bt-max      -0.004116
Bx-med      -0.004494
Bx-min      -0.004747
Bx-max      -0.004315
By-med      -0.004663
By-min      -0.004894
By-max      -0.004341
Bz-med      -0.004822
Bz-min      -0.005019
Bz-max      -0.004407
Phi-mean    -0.002292
Phi-min     -0.007209
Phi-max     -0.002063
Theta-med   -0.006445
Theta-min   -0.006769
Theta-max   -0.004858
Dens-med    -0.004262
Dens-min    -0.004460
Dens-max    -0.003942
Speed-med    0.000860
Speed-min    0.000172
Speed-max    0.001234
Temp-med     0.060189
Temp-min    -0.017895
Temp-max     0.069590
Kp           1.000000
Name: Kp, dtype: float64

--------------------------------------------------

Code:
x = df1.iloc[:, 1:-1]
y = df1.iloc[:, -1]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)

Outputs:

--------------------------------------------------

Code:
x.to_csv('../Code_only/train-tests/x.csv', index = False)
y.to_csv('../Code_only/train-tests/y.csv', index = False)

Outputs:

--------------------------------------------------

Code:
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

multi = LinearRegression().fit(x_train, y_train)
y_pred = multi.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

print(y_test)
y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")

Outputs:
1050    2.333
982     3.333
766     2.000
491     0.667
457     0.333
        ...  
841     1.333
95      0.667
113     2.000
725     0.667
37      0.667
Name: Kp, Length: 333, dtype: float64
Mean Absolute Error (MAE): 0.6790486276752579
Mean Squared Error (MSE): 0.7640443306957228
Root Mean Squared Error (RMSE): 0.8740962937203902
R-squared (R2) Score: 0.5195210365442081

--------------------------------------------------

Code:
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=3)
x_poly = poly.fit_transform(x_train)
reg = LinearRegression().fit(x_poly, y_train)

y_pred = reg.predict(poly.fit_transform(x_test))
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 8.442562673452013
Mean Squared Error (MSE): 744.1389348409579
Root Mean Squared Error (RMSE): 27.27891007428555
R-squared (R2) Score: -466.96120292380056

--------------------------------------------------

Code:
from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.9559879879879881
Mean Squared Error (MSE): 1.5292567387387386
Root Mean Squared Error (RMSE): 1.2366312056303361
R-squared (R2) Score: 0.03830751284038392

--------------------------------------------------

Code:
from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 20, random_state = 0)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)
predicted = y_pred.reshape(len(y_pred),1)

y_pred = [item for sublist in predicted for item in sublist]

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test, y_pred)

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)

# Calculate Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Calculate R-squared (R2) score
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2) Score: {r2}")


Outputs:
Mean Absolute Error (MAE): 0.7335405405405405
Mean Squared Error (MSE): 0.8653285311861862
Root Mean Squared Error (RMSE): 0.9302303645797563
R-squared (R2) Score: 0.4558271830451668

--------------------------------------------------

Code:
# SVM
# ARIMA model (NN)
# LSTM
# Multivariate LSTM (link on slack)
# Multistep LSTM (link sent in slack)
# GRU model (Gated Recurrent Unit)
# Attention Mechanism
# Vanilla LSTM

# Ananya's research papers also included Deep GPR (Gaussian Process Regression)

Outputs:

--------------------------------------------------

Code:
import datetime
log_file_path = '../Logs/models_log.txt'
def log_output_to_file(output_text, log_file_path):
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    divider = '-' * 40  # Line divider
    
    with open(log_file_path, 'a') as log_file:
        log_file.write(f'{timestamp}\n')
        log_file.write(divider + '\n')
        log_file.write(output_text)
        log_file.write('\n\n')


Outputs:

--------------------------------------------------


--------------------------------------------------

--------------------------------------------------

