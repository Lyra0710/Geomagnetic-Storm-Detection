{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 2000/2000 [02:41<00:00, 12.36it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:09<00:00,  9.67s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:50<00:00, 50.71s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data profiling report saved to test_report.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "csv_file = \"/home/maatrika/Desktop/NasaL2/L1Data/Merged_Kp.csv\"  \n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "profile = ProfileReport(df, title=\"Data Profiling Report\", explorative=True)\n",
    "\n",
    "report_file = \"test_report.html\"  \n",
    "profile.to_file(report_file)\n",
    "\n",
    "print(f\"Data profiling report saved to {report_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/maatrika/Desktop/NasaL2/L1Data/Merged_Kp.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['Time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bx', 'By', 'Bz', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
       "       'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
       "       'z', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak',\n",
       "       'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'av', 'aw',\n",
       "       'ax', 'Kp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_corr = corr_matrix = df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     0.083435\n",
       "b    -0.042629\n",
       "c    -0.074825\n",
       "d     0.085428\n",
       "e     0.088948\n",
       "f    -0.031366\n",
       "g    -0.032841\n",
       "h     0.021722\n",
       "i    -0.009589\n",
       "j    -0.025887\n",
       "k    -0.030413\n",
       "l    -0.062703\n",
       "m    -0.069344\n",
       "n    -0.086171\n",
       "o    -0.079996\n",
       "p    -0.040275\n",
       "q     0.035564\n",
       "r     0.077692\n",
       "s     0.152561\n",
       "t     0.184131\n",
       "u     0.186691\n",
       "v     0.168159\n",
       "w     0.177192\n",
       "x     0.230340\n",
       "y     0.251746\n",
       "z     0.226487\n",
       "aa    0.220054\n",
       "ab    0.264909\n",
       "ac    0.288093\n",
       "ad    0.239016\n",
       "ae    0.123457\n",
       "af    0.136917\n",
       "ag    0.115821\n",
       "ah    0.111796\n",
       "ai    0.078167\n",
       "aj    0.046195\n",
       "ak    0.024431\n",
       "al    0.006126\n",
       "am    0.022068\n",
       "an   -0.012219\n",
       "ao   -0.057389\n",
       "ap   -0.042043\n",
       "aq   -0.014172\n",
       "ar    0.051358\n",
       "as    0.026448\n",
       "at   -0.043813\n",
       "au   -0.043813\n",
       "av   -0.043813\n",
       "aw         NaN\n",
       "ax         NaN\n",
       "Kp    1.000000\n",
       "Name: Kp, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['Kp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selector_correlation(cmatrix, threshold):\n",
    "    selected_features = []\n",
    "    feature_score = []\n",
    "    \n",
    "    #kick the non-numeric columns\n",
    "    numeric_columns = cmatrix.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    for column_name in numeric_columns.columns:\n",
    "        score = cmatrix[column_name].corr(cmatrix['Kp']) # correlation with Kp\n",
    "        if abs(score) > threshold:\n",
    "            selected_features.append(column_name)\n",
    "            feature_score.append(['{:3f}'.format(score)])\n",
    "    \n",
    "    result = list(zip(selected_features, feature_score))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w', ['0.533065']),\n",
       " ('x', ['0.564222']),\n",
       " ('y', ['0.560131']),\n",
       " ('z', ['0.532973']),\n",
       " ('aa', ['0.529855']),\n",
       " ('ab', ['0.542513']),\n",
       " ('ac', ['0.527724']),\n",
       " ('Kp', ['1.000000'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_selected = feature_selector_correlation(status_corr, 0.5)\n",
    "features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bx    0\n",
       "By    0\n",
       "Bz    0\n",
       "a     0\n",
       "b     0\n",
       "c     0\n",
       "d     0\n",
       "e     0\n",
       "f     0\n",
       "g     0\n",
       "h     0\n",
       "i     0\n",
       "j     0\n",
       "k     0\n",
       "l     0\n",
       "m     0\n",
       "n     0\n",
       "o     0\n",
       "p     0\n",
       "q     0\n",
       "r     0\n",
       "s     0\n",
       "t     0\n",
       "u     0\n",
       "v     0\n",
       "w     0\n",
       "x     0\n",
       "y     0\n",
       "z     0\n",
       "aa    0\n",
       "ab    0\n",
       "ac    0\n",
       "ad    0\n",
       "ae    0\n",
       "af    0\n",
       "ag    0\n",
       "ah    0\n",
       "ai    0\n",
       "aj    0\n",
       "ak    0\n",
       "al    0\n",
       "am    0\n",
       "an    0\n",
       "ao    0\n",
       "ap    0\n",
       "aq    0\n",
       "ar    0\n",
       "as    0\n",
       "at    0\n",
       "au    0\n",
       "av    0\n",
       "aw    0\n",
       "ax    0\n",
       "Kp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maatrika/Desktop/NasaL2/nasa/lib/python3.10/site-packages/pandas/core/missing.py:94: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= arr == x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature    Importance\n",
      "23       x  8.841962e-02\n",
      "4        e  6.428053e-02\n",
      "28      ac  5.722643e-02\n",
      "20       u  5.019001e-02\n",
      "19       t  4.916028e-02\n",
      "17       r  4.716211e-02\n",
      "24       y  4.495624e-02\n",
      "18       s  3.959195e-02\n",
      "3        d  3.525478e-02\n",
      "0        a  3.317272e-02\n",
      "10       k  3.176716e-02\n",
      "27      ab  3.158427e-02\n",
      "15       p  2.967889e-02\n",
      "16       q  2.805320e-02\n",
      "14       o  2.791863e-02\n",
      "9        j  2.540232e-02\n",
      "22       w  2.452991e-02\n",
      "7        h  2.336991e-02\n",
      "21       v  2.310765e-02\n",
      "2        c  2.304090e-02\n",
      "12       m  2.279546e-02\n",
      "25       z  2.245268e-02\n",
      "29      ad  2.162650e-02\n",
      "13       n  2.150218e-02\n",
      "8        i  2.026520e-02\n",
      "11       l  1.983665e-02\n",
      "26      aa  1.881938e-02\n",
      "6        g  1.289605e-02\n",
      "30      ae  9.706481e-03\n",
      "5        f  9.694038e-03\n",
      "31      af  8.685716e-03\n",
      "32      ag  7.771004e-03\n",
      "34      ai  5.826795e-03\n",
      "35      aj  5.292988e-03\n",
      "33      ah  4.958856e-03\n",
      "37      al  3.251659e-03\n",
      "36      ak  2.623759e-03\n",
      "38      am  2.144707e-03\n",
      "42      aq  6.053755e-04\n",
      "43      ar  3.653959e-04\n",
      "40      ao  3.398567e-04\n",
      "1        b  2.373759e-04\n",
      "39      an  2.137550e-04\n",
      "44      as  1.513252e-04\n",
      "41      ap  6.878990e-05\n",
      "46      au  5.231850e-07\n",
      "45      at  0.000000e+00\n",
      "47      av  0.000000e+00\n",
      "48      aw  0.000000e+00\n",
      "49      ax  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = df.replace('#NAME?', pd.NA)\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=['number'])\n",
    "\n",
    "X = numeric_columns.drop(columns=['Kp']) \n",
    "y = df['Kp']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_imputed, y)\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection using RFE Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maatrika/Desktop/NasaL2/nasa/lib/python3.10/site-packages/pandas/core/missing.py:94: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= arr == x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['Time', 'Bx', 'By', 'Bz'], dtype='object')\n",
      "   Feature  Ranking\n",
      "17       r        1\n",
      "23       x        2\n",
      "4        e        3\n",
      "19       t        4\n",
      "20       u        5\n",
      "28      ac        6\n",
      "10       k        7\n",
      "24       y        8\n",
      "3        d        9\n",
      "18       s       10\n",
      "15       p       11\n",
      "27      ab       12\n",
      "0        a       13\n",
      "14       o       14\n",
      "7        h       15\n",
      "22       w       16\n",
      "16       q       17\n",
      "9        j       18\n",
      "2        c       19\n",
      "11       l       20\n",
      "21       v       21\n",
      "13       n       22\n",
      "25       z       23\n",
      "29      ad       24\n",
      "12       m       25\n",
      "26      aa       26\n",
      "8        i       27\n",
      "6        g       28\n",
      "30      ae       29\n",
      "31      af       30\n",
      "5        f       31\n",
      "32      ag       32\n",
      "35      aj       33\n",
      "34      ai       34\n",
      "37      al       35\n",
      "33      ah       36\n",
      "38      am       37\n",
      "36      ak       38\n",
      "42      aq       39\n",
      "1        b       40\n",
      "39      an       41\n",
      "40      ao       42\n",
      "43      ar       43\n",
      "41      ap       44\n",
      "44      as       45\n",
      "45      at       46\n",
      "47      av       47\n",
      "46      au       48\n",
      "48      aw       49\n",
      "49      ax       50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "df1 = df.replace('#NAME?', np.nan)\n",
    "\n",
    "X = df1.drop(columns=['Kp']) \n",
    "y = df1['Kp']\n",
    "\n",
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)\n",
    "\n",
    "X_numeric = X.select_dtypes(include=['number'])\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_numeric)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rfe = RFE(estimator=rf, n_features_to_select=1)\n",
    "\n",
    "rfe.fit(X_imputed, y)\n",
    "\n",
    "feature_ranking = rfe.ranking_\n",
    "\n",
    "ranking_df = pd.DataFrame({'Feature': X_numeric.columns, 'Ranking': feature_ranking})\n",
    "\n",
    "ranking_df = ranking_df.sort_values(by='Ranking')\n",
    "\n",
    "print(ranking_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - RF Feature Importance:\n",
    "\n",
    "Features: 'x', 'e', 'ac', 'u', 't', 'r', 'y', 's', 'd', 'a', 'k'\n",
    "\n",
    "### Method 2 - RFE Feature Ranking:\n",
    "\n",
    "Features: \"r\", \"x\", \"t\", \"u\", \"ac\", \"k\", \"y\", \"d\", \"s\"\n",
    "\n",
    "### Correlation Values with Kp:\n",
    "\n",
    "1. 'x' - Correlation: 0.564222\n",
    "2. 'y' - Correlation: 0.560131\n",
    "3. 'ab' - Correlation: 0.542513\n",
    "4. 'w' - Correlation: 0.533065\n",
    "5. 'z' - Correlation: 0.532973\n",
    "6. 'aa' - Correlation: 0.529855\n",
    "7. 'ac' - Correlation: 0.527724\n",
    "\n",
    "\n",
    "### Considering both the feature importance rankings and correlation values, you can prioritize the following features:\n",
    "\n",
    "1. 'x' (Method 1 and Correlation)\n",
    "2. 'y' (Method 2 and Correlation)\n",
    "3. 'ac' (Method 1 and Correlation)\n",
    "4. 'ab' (Correlation)\n",
    "5. 'w' (Correlation)\n",
    "6. 'z' (Correlation)\n",
    "7. 'aa' (Correlation)\n",
    "8. 'Bx', 'By', and 'Bz' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('/home/maatrika/Desktop/NasaL2/L1Data/Merged_Kp.csv') \n",
    "\n",
    "numeric_columns = df.select_dtypes(include=[np.number])\n",
    "X = numeric_columns.drop(columns=['Kp'])  \n",
    "y = numeric_columns['Kp']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "#define the GRU model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x.unsqueeze(2), h0)  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = X_train_tensor.shape[1]  \n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = GRUModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "#define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    #backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    mse = mean_squared_error(y_test_tensor, test_outputs)\n",
    "    r2 = r2_score(y_test_tensor, test_outputs)\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "    \n",
    "#error with tensor values --> loss values = NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/maatrika/Desktop/NasaL2/L1Data/Merged_Kp.csv') \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df = pd.read_csv('/home/maatrika/Desktop/NasaL2/L1Data/Merged_Kp.csv')  \n",
    "\n",
    "\n",
    "df['Bx'] = pd.to_numeric(df['Bx'], errors='coerce')\n",
    "df['By'] = pd.to_numeric(df['By'], errors='coerce')\n",
    "df['Bz'] = pd.to_numeric(df['Bz'], errors='coerce')\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=[np.number])\n",
    "X = numeric_columns.drop(columns=['Kp'])  \n",
    "y = numeric_columns['Kp']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "selected_features = ['x', 'y', 'ac', 'ab', 'w', 'z', 'aa', 'Bx', 'By', 'Bz']\n",
    "\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "#convert data to PyTorch tensors and add an extra dimension for sequence length\n",
    "X_train_tensor = torch.unsqueeze(torch.tensor(X_train_selected.values, dtype=torch.float32), 1)\n",
    "X_test_tensor = torch.unsqueeze(torch.tensor(X_test_selected.values, dtype=torch.float32), 1)\n",
    "y_train_tensor = torch.unsqueeze(torch.tensor(y_train.values, dtype=torch.float32), 1)\n",
    "y_test_tensor = torch.unsqueeze(torch.tensor(y_test.values, dtype=torch.float32), 1)\n",
    "\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        out, _ = self.gru(x)  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = len(selected_features)\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "\n",
    "model = GRUModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "#define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "#training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    #backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    \n",
    "    if torch.isnan(y_test_tensor).any() or torch.isnan(test_outputs).any():\n",
    "        print(\"Warning: NaN values detected in the tensors.\")\n",
    "    \n",
    "    mse = mean_squared_error(y_test_tensor.numpy(), test_outputs.numpy())\n",
    "    r2 = r2_score(y_test_tensor.numpy(), test_outputs.numpy())\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"R-squared (R2) Score: {r2:.4f}\")\n",
    "    \n",
    "    \n",
    "#erroe being input in 2-D but tensors as 3-D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Bx', 'By', 'Bz', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
      "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
      "       'x', 'y', 'z', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'ag', 'ah', 'ai',\n",
      "       'aj', 'ak', 'al', 'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au',\n",
      "       'av', 'aw', 'ax', 'Kp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
